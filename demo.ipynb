{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of final language-specific code - Turkish\n",
    "\n",
    "**LNG 409 Fall 2024**\n",
    "\n",
    "Author: Hee Joong Choi, Yuzhang Fu, Xin You\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pynini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will walkthrough our final code named **transducer_tur**, which implements vowel harmony correction for Turkish noun plural and verb progressive suffixes using Finite-State Transducers (FSTs) via the `pynini` library. We will demonstrate the tweaks we made, the logistics of the code, and the performance of these transducers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this code, install pynini, a library for building and running weighted finite-state transducers.\n",
    "\n",
    "```Python\n",
    "!pip install pynini\n",
    "```\n",
    "\n",
    "**Note**: Throughout the project, we are only able import the pynini library on google colab. For instance, it is suggested to upload `transducer_tur.ipynb` along with `data/tur.out` and `data/tur.dev` to google drive and run the code. However, we have also attached `trasducer_tur.py` in our github repository for you to check."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defined functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vowel categorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created two helper functions that categorize vowels in Turkish words:\n",
    "\n",
    "`n_vowel_categorize(lemma)` determines the frontness and roundness of the last vowel in a lemma, where **'ö, ü'** are front rounded vowels, **'e,i'** are front unrounded vowels, **'o, u'** are back rounded vowels, and **'a, ı'** are back unrounded vowels.\n",
    "\n",
    "```python\n",
    "def n_vowel_categorize(lemma):\n",
    "    for char in reversed(lemma):\n",
    "        if char in \"öü\":\n",
    "            return {\"frontness\": True, \"roundness\": True}\n",
    "        elif char in \"ei\":\n",
    "            return {\"frontness\": True, \"roundness\": False}\n",
    "        elif char in \"ou\":\n",
    "            return {\"frontness\": False, \"roundness\": True}\n",
    "        elif char in \"aı\":\n",
    "            return {\"frontness\": False, \"roundness\": False}\n",
    "```\n",
    "\n",
    "`v_vowel_categorize(lemma)` finds the second-to-last vowel in the lemma to handle progressive suffix rules with the same vowel categorization rules above.\n",
    "\n",
    "```python\n",
    "def v_vowel_categorize(lemma):\n",
    "    vowels = \"öüeiouaı\"\n",
    "    n = 0\n",
    "    for char in reversed(lemma):\n",
    "        if char in vowels:\n",
    "            n += 1\n",
    "            if n == 2:\n",
    "                if char in \"öü\":\n",
    "                    return {\"frontness\": True, \"roundness\": True}\n",
    "                elif char in \"ei\":\n",
    "                    return {\"frontness\": True, \"roundness\": False}\n",
    "                elif char in \"ou\":\n",
    "                    return {\"frontness\": False, \"roundness\": True}\n",
    "                elif char in \"aı\":\n",
    "                    return {\"frontness\": False, \"roundness\": False}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plural Suffix Correction for Nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction of transducers\n",
    "```python\n",
    "turkish_alphabet = \"abcçdefgğhıijklmnoöprsştuüvyz \" # Added \" \"(space) to include compounds like \"sözdizimsel tuzlerde\"\n",
    "sigma = pynini.union(*turkish_alphabet).closure()\n",
    "```\n",
    "The Turkish alphabet is defined, including a space character to handle multi-word compounds. `sigma` is created to match any valid Turkish word.\n",
    "\n",
    "```python\n",
    "plural_correction_rule_a = pynini.cdrewrite(\n",
    "        pynini.cross(\"e\", \"a\"),\n",
    "        \"l\",\n",
    "        \"r\",\n",
    "        sigma)\n",
    "\n",
    "plural_correction_rule_e = pynini.cdrewrite(\n",
    "        pynini.cross(\"a\", \"e\"),\n",
    "        \"l\",\n",
    "        \"r\",\n",
    "        sigma)\n",
    "```\n",
    "Two rewrite rules are defined:\n",
    "1. **`plural_correction_rule_a`**: Converts \"e\" to \"a\" when the suffix should be `lar` (used for back vowels).\n",
    "2. **`plural_correction_rule_e`**: Converts \"a\" to \"e\" when the suffix should be `ler` (used for front vowels).\n",
    "\n",
    "These rules ensure suffix alignment with Turkish vowel harmony principles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for noun processing\n",
    "```python\n",
    "n_n_pl = 0 # counter for total number or words\n",
    "c_n_pl = 0 # counter for correct words\n",
    "\n",
    "for i, line in enumerate(tur_out):\n",
    "  lemma, msd, inflected = line[:3]\n",
    "  correct = dev[i]\n",
    "\n",
    "  if msd.startswith(\"N\") and '(PL' in msd:\n",
    "    v_cat = n_vowel_categorize(lemma)\n",
    "```\n",
    "First, we check for nouns and plural forms by creating a filter that only process entries with part-of-speech `N` (noun) and containing `(PL` (plural) in `msd`. Then, we categorize vowel harmony by using the `n_vowel_categorize` function to determine the vowel frontness of the lemma.\n",
    "\n",
    "```python\n",
    "    if v_cat[\"frontness\"] == False and \"ler\" in inflected:\n",
    "      output = inflected @ plural_correction_rule_a\n",
    "      paths = list(output.paths().ostrings())\n",
    "      correction = paths[0]\n",
    "      print(lemma, inflected, \"→\", correction, correct == correction)\n",
    "      n_n_pl += 1\n",
    "      if correct == correction:\n",
    "        c_n_pl += 1\n",
    "\n",
    "    elif v_cat[\"frontness\"] == True and \"lar\" in inflected:\n",
    "      output = inflected @ plural_correction_rule_e\n",
    "      paths = list(output.paths().ostrings())\n",
    "      correction = paths[0]\n",
    "      print(lemma, inflected, \"→\", correction, correct == correction)\n",
    "      n_n_pl += 1\n",
    "      if correct == correction:\n",
    "        c_n_pl += 1\n",
    "\n",
    "    else:\n",
    "      correction = inflected\n",
    "\n",
    "  print(\"--------------------------------\")\n",
    "  print(\"Number of words identified:\", n_n_pl)\n",
    "  print(\"Number of words corrected:\", c_n_pl)\n",
    "```\n",
    "Next, we apply plural suffix rules which correct `ler` to `lar` using `plural_correction_rule_a` for back vowels and correct `lar` to `ler` using `plural_correction_rule_e` for front vowels. In the end, we compare the corrected form with the (`correct`) and track the total (`n`) and successful corrections (`c`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample output\n",
    "The output shows each lemma, its original inflected form, the corrected form, and whether the correction matches the expected form (`True` or `False`).\n",
    "\n",
    "Example:\n",
    "```\n",
    "anahtarlık anahtarlıklerimize → anahtarlıklarimize False\n",
    "asimptot asimptotlerimizden → asimptotlarimizden False\n",
    "küçüklük küçüklüklar → küçüklükler True\n",
    "otel otellarını → otellerını False\n",
    "sözdizimsel tuz sözdizimsel tuzler → sözdizimsel tuzlar True\n",
    "```\n",
    "\n",
    "At the end, it prints the total processed cases (`n`) and successful corrections (`c`):\n",
    "```\n",
    "Number of words identified: 31\n",
    "Number of words corrected: 2\n",
    "```\n",
    "\n",
    "**2 out of 31** cases were corrected successfully. \n",
    "- Reason for low success rate: While the plural suffix (lar/ler) is corrected, subsequent suffixes (e.g., possessive or case suffixes) remain unprocessed. These additional suffixes also require adjustments to align with vowel harmony rules, which the current implementation does not address."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Progressive Suffix Correction for Verbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction of transducers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for verb processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
